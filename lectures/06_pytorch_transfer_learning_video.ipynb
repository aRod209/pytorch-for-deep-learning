{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAIx5MQMWIkXfvma7jeqVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aRod209/pytorch-for-deep-learning/blob/main/lectures/06_pytorch_transfer_learning_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06. PyTorch Transfer Learning\n",
        "\n",
        "What is transfer learning?\n",
        "\n",
        "Transfer learning involves taking the parameters of what one model has learned on another dataset and applying to our own problem.\n",
        "\n",
        "* Pretrained model = foundation model"
      ],
      "metadata": {
        "id": "0bWRxfGUgdTg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-zkqBXSgXQY",
        "outputId": "dee81389-b36c-4e55-ff31-1a26d2d0ce25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "0.17.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "# I know we have versions that are greater than these versions, but I just\n",
        "# want to run the below code anyways to know how to update to targeted versions.\n",
        "\n",
        "try:\n",
        "  assert int(torch.__version__.split('.')[0]) >= 1, 'torch version should be at least version 1'\n",
        "\n",
        "  if int(torch.__version__.split('.')[0]) == 1:\n",
        "    assert int(torch.__version__.split('.')[1]) >= 12, 'torch version should be 1.12+'\n",
        "\n",
        "  if int(torchvision.__version__.split('.')[0]) == 0:\n",
        "    assert int(torchvision.__version__.split('.')[1]) >= 13, 'torchvision version should be 0.13+'\n",
        "except:\n",
        "  print(f'[INFO] torch/torchvision version not as required, installing nightly versions.')\n",
        "  !pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
        "finally:\n",
        "  print(f'torch version: {torch.__version__}')\n",
        "  print(f'torchvision version: {torchvision.__version__}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH-I4PBuhY-m",
        "outputId": "abf31582-32a0-4cbd-ba79-39fdf890b064"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.2.1+cu121\n",
            "torchvision version: 0.17.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the versions of `torch` and `torchvision` we're after, let's import the code we've written in previous sections so that we don't have to write it all again."
      ],
      "metadata": {
        "id": "IJtDuSLAialE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to get torchinfo, installit if it does not work\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "  !pip install -q  torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "# Try to import the going modular directory, download it from GitHub if it does not work\n",
        "try:\n",
        "  from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "  # Get the going_modular scripts\n",
        "  print(\"[INFO] Couldn't find foing_modular scripts... downloading them from GitHub.\")\n",
        "  !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "  !mv pytorch-deep-learning/going_modular .\n",
        "  !rm -rf pytorch-deep-learning\n",
        "  from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "n7jaD9VRi1pB",
        "outputId": "2ee5e08e-c7ff-49b7-e634-5bdeec2224ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find foing_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 30.24 MiB/s, done.\n",
            "Resolving deltas: 100% (2372/2372), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "fjOUoD5kmqY1",
        "outputId": "cbb58b58-3443-4569-9553-fb6efed105cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "1pit-Nb4m7dI",
        "outputId": "075ddc2c-e5bb-492c-9a75-1d77cff5f68d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "We need our pzza, steak, sushi data to build a transfer learning model on."
      ],
      "metadata": {
        "id": "BZaqj79hm9bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# Setup data path\n",
        "data_path = Path('data/')\n",
        "image_path = data_path / 'pizza_steak_sushi' # images from a subset of classes from the Food101 dataset\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f'{image_path} directory exists, skipping re-download')\n",
        "else:\n",
        "  print(f'Did not find {image_path}, downloading it...')\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Download pizza, steak, sushi data\n",
        "  with open(data_path / 'pizza_steak_sushi.zip', 'wb') as f:\n",
        "    response = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
        "    print('Downloading pizza, steak, sushi, data...')\n",
        "    f.write(response.content)\n",
        "\n",
        "    # unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
        "      print('Unzipping pizza, steak, sushi data...')\n",
        "      zip_ref.extractall(image_path)\n",
        "\n",
        "      # Remove .zip file\n",
        "      os.remove(data_path / 'pizza_steak_sushi.zip')"
      ],
      "metadata": {
        "id": "vW4STpEu3wI6",
        "outputId": "eedd5b03-6961-4891-cd24-befc1fe55b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi, downloading it...\n",
            "Downloading pizza, steak, sushi, data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directory path\n",
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "EBhKA42o5yLi",
        "outputId": "1c18f023-17f7-4eb8-adb8-4a6727d65b6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders\n",
        "\n",
        "Now we've got some data. Now we want to turn it into PyTorch `DataLoader`s\n",
        "\n",
        "To do so, we can use `data_setup.py` and the `create_dataloaders()` function we maid in 05. PyTorch Going Modular\n",
        "\n",
        "There's one thing we have to think about when loading: how to **transform** it?\n",
        "\n",
        "And with `torchvision` 0.13+ there's two ways to do this:\n",
        "\n",
        "1. Manually created transforms - you define what tranforms you want your data to go through\n",
        "2. Automatically created transforms - the transforms for your dat are defined by the model you'd like to use.\n",
        "\n",
        "Important point: when using a pretrained model, it's important that your data (including your custom data) that yo pass through it is **transformed** in the same way that the data the model was trained on.\n"
      ],
      "metadata": {
        "id": "FY2opncs55eB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Creating a transform for `torchvision.models` (manual creation)\n",
        "\n",
        "`torchvision.models` contains pretrained models (models ready for transfer learning) right within `torchvision`.\n",
        "\n",
        ">All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. You can use the following transform to normalize:"
      ],
      "metadata": {
        "id": "ZMj7NGHaYXLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # resize image to 224, 224 (height x width)\n",
        "    transforms.ToTensor(), # get images into range [0, 1]\n",
        "    normalize # make sure images have the same distribution as ImageNet (where our pretrained models have been trained)\n",
        "    ])"
      ],
      "metadata": {
        "id": "ByveNH8VcNbx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transforms,\n",
        "                                                                               batch_size=32)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dUi8OfPdeWW",
        "outputId": "4a577063-e3b6-4321-e515-7db6fbc7a113"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7d47f74f4e80>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7d47dd471060>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Creating a transform for `torchvision.models` (auto creation)\n",
        "\n",
        "As of `torchvision` v0.133+ there is now support for automatic data transform creation based on the pretrained model weights you're using."
      ],
      "metadata": {
        "id": "5vnhquP5d0lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "_hFZObt0sRnh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" = best available weights\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZRds5f79dDF",
        "outputId": "d18db486-37bb-431b-e070-4f92d74d155c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet_B0_Weights.IMAGENET1K_V1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE76YzMQ-d0Q",
        "outputId": "fed723ed-4260-45bd-e7f2-256f901ae1d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BICUBIC\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders using automatic transforms\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=auto_transforms,\n",
        "                                                                               batch_size=32)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_IQfHcr-u4N",
        "outputId": "930cadd2-eec8-43f6-98d9-f5ab384bb807"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7d47dd472110>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7d47dd4703a0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Getting a pretrained model\n",
        "\n",
        "There are various places to get a pretrained model, such as:\n",
        "1. PyTorch domain libraries\n",
        "2. Libraries like `timm` (torch image models)\n",
        "3. HuggingFace Hub (for plenty of different models)\n",
        "4. Paperswithcode (for models across different problem spaces/domains)"
      ],
      "metadata": {
        "id": "B1JuIDnL_NWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Which pretrained model should you use?\n",
        "\n",
        "*Experiment, experiment, experiment~*\n",
        "\n",
        "The whole idea of transfer learning: take an already well-performing model from a problem space similar to your own and then customize to your own problem.\n",
        "\n",
        "Three things to consider:\n",
        "1. Speed - how fast does it run?\n",
        "2. Size - how big is the model?\n",
        "3. Performance - how well does it go on your chosen problem (e.g. how well does it classify food images? for FoodVision mini?)\n",
        "\n",
        "Where does the model live?\n",
        "\n",
        "Is it on device? (like a self-driving car)\n",
        "\n",
        "Or does it live on a server?\n",
        "\n",
        "Looking at https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights\n",
        "\n",
        "Which model should we choose?\n",
        "\n",
        "For our case (deploying FoodVision Mini on a mobile device), it looks like kEFFNetB0 is one of our best options in terms of performance vs. size.\n",
        "\n",
        "However, in light of [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html), if we had infinite compute, we'd likely pick the biggest model + most parameters + most general we could."
      ],
      "metadata": {
        "id": "Ii1gyUSeDKVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Setting up a pretrained model\n",
        "\n",
        "Want to an instance of a pretrained EffNetB0 -https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b0.html#efficientnet-b0"
      ],
      "metadata": {
        "id": "qFiS8PxHDuw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OLD method of creating a pretrained model (prior to torchvision v0.13)\n",
        "# model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# New method of creating a pretrained model (torchvision v0.13+)\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \".DEFAULT\" = best available weights\n",
        "model = torchvision.models.efficientnet_b0(weights=weights)\n",
        "model"
      ],
      "metadata": {
        "id": "izugUaIAe0W8",
        "outputId": "e8c528f4-20c6-431d-ee43-d1ab2ea5b478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=True)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.features"
      ],
      "metadata": {
        "id": "QdZwWrfUfCOB",
        "outputId": "707e9bfe-b043-4401-feac-d2b38c172a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2dNormActivation(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SiLU(inplace=True)\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (2): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (3): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (4): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "    )\n",
              "    (3): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (8): Conv2dNormActivation(\n",
              "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SiLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.avgpool"
      ],
      "metadata": {
        "id": "QRxLS0-YknS3",
        "outputId": "e1fd004e-49b7-4e84-e17c-168a0f151674",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaptiveAvgPool2d(output_size=1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "id": "JQlZRDDKkqHz",
        "outputId": "b2823834-0536-4031-de37-eafd6cd0d6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.2, inplace=True)\n",
              "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQZepdlUkuoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}