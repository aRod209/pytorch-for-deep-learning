{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTTyWNW5fxuIG2NoNg8k7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aRod209/pytorch-for-deep-learning/blob/main/lectures/06_pytorch_transfer_learning_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06. PyTorch Transfer Learning\n",
        "\n",
        "What is transfer learning?\n",
        "\n",
        "Transfer learning involves taking the parameters of what one model has learned on another dataset and applying to our own problem.\n",
        "\n",
        "* Pretrained model = foundation model"
      ],
      "metadata": {
        "id": "0bWRxfGUgdTg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-zkqBXSgXQY",
        "outputId": "db4b6431-13b2-432b-df58-06894de79bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "0.17.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "# I know we have versions that are greater than these versions, but I just\n",
        "# want to run the below code anyways to know how to update to targeted versions.\n",
        "\n",
        "try:\n",
        "  assert int(torch.__version__.split('.')[0]) >= 1, 'torch version should be at least version 1'\n",
        "\n",
        "  if int(torch.__version__.split('.')[0]) == 1:\n",
        "    assert int(torch.__version__.split('.')[1]) >= 12, 'torch version should be 1.12+'\n",
        "\n",
        "  if int(torchvision.__version__.split('.')[0]) == 0:\n",
        "    assert int(torchvision.__version__.split('.')[1]) >= 13, 'torchvision version should be 0.13+'\n",
        "except:\n",
        "  print(f'[INFO] torch/torchvision version not as required, installing nightly versions.')\n",
        "  !pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
        "finally:\n",
        "  print(f'torch version: {torch.__version__}')\n",
        "  print(f'torchvision version: {torchvision.__version__}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH-I4PBuhY-m",
        "outputId": "6644499f-fb64-4413-f6bd-fb82859e6c71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.2.1+cu121\n",
            "torchvision version: 0.17.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the versions of `torch` and `torchvision` we're after, let's import the code we've written in previous sections so that we don't have to write it all again."
      ],
      "metadata": {
        "id": "IJtDuSLAialE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to get torchinfo, installit if it does not work\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "  !pip install -q  torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "# Try to import the going modular directory, download it from GitHub if it does not work\n",
        "try:\n",
        "  from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "  # Get the going_modular scripts\n",
        "  print(\"[INFO] Couldn't find foing_modular scripts... downloading them from GitHub.\")\n",
        "  !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "  !mv pytorch-deep-learning/going_modular .\n",
        "  !rm -rf pytorch-deep-learning\n",
        "  from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "n7jaD9VRi1pB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "fjOUoD5kmqY1",
        "outputId": "d11ad819-60b7-41b4-879d-b1fa588e77fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "1pit-Nb4m7dI",
        "outputId": "27c1da19-cf23-483c-a194-0e2b0140c757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "We need our pzza, steak, sushi data to build a transfer learning model on."
      ],
      "metadata": {
        "id": "BZaqj79hm9bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# Setup data path\n",
        "data_path = Path('data/')\n",
        "image_path = data_path / 'pizza_steak_sushi' # images from a subset of classes from the Food101 dataset\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f'{image_path} directory exists, skipping re-download')\n",
        "else:\n",
        "  print(f'Did not find {image_path}, downloading it...')\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Download pizza, steak, sushi data\n",
        "  with open(data_path / 'pizza_steak_sushi.zip', 'wb') as f:\n",
        "    response = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
        "    print('Downloading pizza, steak, sushi, data...')\n",
        "    f.write(response.content)\n",
        "\n",
        "    # unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
        "      print('Unzipping pizza, steak, sushi data...')\n",
        "      zip_ref.extractall(image_path)\n",
        "\n",
        "      # Remove .zip file\n",
        "      os.remove(data_path / 'pizza_steak_sushi.zip')"
      ],
      "metadata": {
        "id": "vW4STpEu3wI6",
        "outputId": "d3318a6f-016c-43f7-a2ef-6d47c5b54589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists, skipping re-download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directory path\n",
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "EBhKA42o5yLi",
        "outputId": "76b13d99-1c25-43e1-8d19-58dee8a7b450",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders\n",
        "\n",
        "Now we've got some data. Now we want to turn it into PyTorch `DataLoader`s\n",
        "\n",
        "To do so, we can use `data_setup.py` and the `create_dataloaders()` function we maid in 05. PyTorch Going Modular\n",
        "\n",
        "There's one thing we have to think about when loading: how to **transform** it?\n",
        "\n",
        "And with `torchvision` 0.13+ there's two ways to do this:\n",
        "\n",
        "1. Manually created transforms - you define what tranforms you want your data to go through\n",
        "2. Automatically created transforms - the transforms for your dat are defined by the model you'd like to use.\n",
        "\n",
        "Important point: when using a pretrained model, it's important that your data (including your custom data) that yo pass through it is **transformed** in the same way that the data the model was trained on.\n"
      ],
      "metadata": {
        "id": "FY2opncs55eB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Creating a transform for `torchvision.models` (manual creation)\n",
        "\n",
        "`torchvision.models` contains pretrained models (models ready for transfer learning) right within `torchvision`.\n",
        "\n",
        ">All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. You can use the following transform to normalize:"
      ],
      "metadata": {
        "id": "ZMj7NGHaYXLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # resize image to 224, 224 (height x width)\n",
        "    transforms.ToTensor(), # get images into range [0, 1]\n",
        "    normalize # make sure images have the same distribution as ImageNet (where our pretrained models have been trained)\n",
        "    ])"
      ],
      "metadata": {
        "id": "ByveNH8VcNbx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transforms,\n",
        "                                                                               batch_size=32)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dUi8OfPdeWW",
        "outputId": "08a363cd-3983-4b9a-ed58-2b644682b874"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7eda2c41de10>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7eda2c41c5b0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Creating a transform for `torchvision.models` (auto creation)\n",
        "\n",
        "As of `torchvision` v0.133+ there is now support for automatic data transform creation based on the pretrained model weights you're using."
      ],
      "metadata": {
        "id": "5vnhquP5d0lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "_hFZObt0sRnh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" = best available weights\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZRds5f79dDF",
        "outputId": "38ac995d-5977-4c5c-97d3-818db5dda657"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet_B0_Weights.IMAGENET1K_V1"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE76YzMQ-d0Q",
        "outputId": "fd79336d-8e27-43bd-a1d7-bbc063ca3225"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BICUBIC\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders using automatic transforms\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=auto_transforms,\n",
        "                                                                               batch_size=32)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_IQfHcr-u4N",
        "outputId": "66d2c08d-bd28-4614-9c89-2532b9b91a4a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7eda2c41d060>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7eda2c41edd0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Getting a pretrained model\n",
        "\n",
        "There are various places to get a pretrained model, such as:\n",
        "1. PyTorch domain libraries\n",
        "2. Libraries like `timm` (torch image models)\n",
        "3. HuggingFace Hub (for plenty of different models)\n",
        "4. Paperswithcode (for models across different problem spaces/domains)"
      ],
      "metadata": {
        "id": "B1JuIDnL_NWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Which pretrained model should you use?\n",
        "\n",
        "*Experiment, experiment, experiment~*\n",
        "\n",
        "The whole idea of transfer learning: take an already well-performing model from a problem space similar to your own and then customize to your own problem.\n",
        "\n",
        "Three things to consider:\n",
        "1. Speed - how fast does it run?\n",
        "2. Size - how big is the model?\n",
        "3. Performance - how well does it go on your chosen problem (e.g. how well does it classify food images? for FoodVision mini?)\n",
        "\n",
        "Where does the model live?\n",
        "\n",
        "Is it on device? (like a self-driving car)\n",
        "\n",
        "Or does it live on a server?\n",
        "\n",
        "Looking at https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights\n",
        "\n",
        "Which model should we choose?\n",
        "\n",
        "For our case (deploying FoodVision Mini on a mobile device), it looks like kEFFNetB0 is one of our best options in terms of performance vs. size.\n",
        "\n",
        "However, in light of [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html), if we had infinite compute, we'd likely pick the biggest model + most parameters + most general we could."
      ],
      "metadata": {
        "id": "Ii1gyUSeDKVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Setting up a pretrained model\n",
        "\n",
        "Want to an instance of a pretrained EffNetB0 -https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b0.html#efficientnet-b0"
      ],
      "metadata": {
        "id": "qFiS8PxHDuw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OLD method of creating a pretrained model (prior to torchvision v0.13)\n",
        "# model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# New method of creating a pretrained model (torchvision v0.13+)\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \".DEFAULT\" = best available weights\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "izugUaIAe0W8",
        "outputId": "a65a11af-7f64-4bf7-ff02-38627229f3f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=True)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.features"
      ],
      "metadata": {
        "id": "QdZwWrfUfCOB",
        "outputId": "d0856fc4-e481-4768-ddc6-1d69926d439f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2dNormActivation(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SiLU(inplace=True)\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (2): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (3): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (4): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "    )\n",
              "    (1): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "    )\n",
              "    (2): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "    )\n",
              "    (3): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): MBConv(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): SiLU(inplace=True)\n",
              "          (scale_activation): Sigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "    )\n",
              "  )\n",
              "  (8): Conv2dNormActivation(\n",
              "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SiLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.avgpool"
      ],
      "metadata": {
        "id": "QRxLS0-YknS3",
        "outputId": "19bc4d87-baf8-4264-aa05-cf7f55943f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaptiveAvgPool2d(output_size=1)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "id": "JQlZRDDKkqHz",
        "outputId": "0bc780b2-886e-4870-e14b-eff2597c139f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.2, inplace=True)\n",
              "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Getting a summary of our model with `torchinfo.summary()`"
      ],
      "metadata": {
        "id": "GQZepdlUkuoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print with torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "summary(model=model,\n",
        "        input_size=(1, 3, 224, 224), # Example of [batch_size, color_channels, height, width]\n",
        "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "        col_width=20,\n",
        "        row_settings=['var_names'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQypOVScZ_fz",
        "outputId": "e01fda95-608e-494b-c265-166a9ece216c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 1000]            --                   True\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1280, 7, 7]      --                   True\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   True\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    864                  True\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   True\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    1,448                True\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   True\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      6,004                True\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      10,710               True\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 40, 28, 28]      --                   True\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 40, 28, 28]      15,350               True\n",
              "│    │    └─MBConv (1)                                       [1, 40, 28, 28]      [1, 40, 28, 28]      31,290               True\n",
              "│    └─Sequential (4)                                        [1, 40, 28, 28]      [1, 80, 14, 14]      --                   True\n",
              "│    │    └─MBConv (0)                                       [1, 40, 28, 28]      [1, 80, 14, 14]      37,130               True\n",
              "│    │    └─MBConv (1)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      102,900              True\n",
              "│    │    └─MBConv (2)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      102,900              True\n",
              "│    └─Sequential (5)                                        [1, 80, 14, 14]      [1, 112, 14, 14]     --                   True\n",
              "│    │    └─MBConv (0)                                       [1, 80, 14, 14]      [1, 112, 14, 14]     126,004              True\n",
              "│    │    └─MBConv (1)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     208,572              True\n",
              "│    │    └─MBConv (2)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     208,572              True\n",
              "│    └─Sequential (6)                                        [1, 112, 14, 14]     [1, 192, 7, 7]       --                   True\n",
              "│    │    └─MBConv (0)                                       [1, 112, 14, 14]     [1, 192, 7, 7]       262,492              True\n",
              "│    │    └─MBConv (1)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n",
              "│    │    └─MBConv (2)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n",
              "│    │    └─MBConv (3)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n",
              "│    └─Sequential (7)                                        [1, 192, 7, 7]       [1, 320, 7, 7]       --                   True\n",
              "│    │    └─MBConv (0)                                       [1, 192, 7, 7]       [1, 320, 7, 7]       717,232              True\n",
              "│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]       [1, 1280, 7, 7]      --                   True\n",
              "│    │    └─Conv2d (0)                                       [1, 320, 7, 7]       [1, 1280, 7, 7]      409,600              True\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]      [1, 1280, 7, 7]      2,560                True\n",
              "│    │    └─SiLU (2)                                         [1, 1280, 7, 7]      [1, 1280, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]      [1, 1280, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1280]            [1, 1000]            --                   True\n",
              "│    └─Dropout (0)                                           [1, 1280]            [1, 1280]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1280]            [1, 1000]            1,281,000            True\n",
              "============================================================================================================================================\n",
              "Total params: 5,288,548\n",
              "Trainable params: 5,288,548\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 385.87\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 107.89\n",
              "Params size (MB): 21.15\n",
              "Estimated Total Size (MB): 129.64\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Freezing the base model and changing the output layer to suit our needs\n",
        "\n",
        "With a feature extractor model, typically you will \"freeze\" the base layers of a pretrained/foundation model and update the output layers to suit your own problem."
      ],
      "metadata": {
        "id": "l-Jcd2fadIol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all of the base layers in EffNetB0\n",
        "for param in model.features.parameters():\n",
        "  #print(param)\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "_DAQunmshQKm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(1, 3, 224, 224), # Example of [batch_size, color_channels, height, width]\n",
        "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "        col_width=20,\n",
        "        row_settings=['var_names'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8nPd1sehvc3",
        "outputId": "fc0810e2-6d4c-4ee5-ee46-3a6750f19f1e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 1000]            --                   Partial\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1280, 7, 7]      --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 40, 28, 28]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 40, 28, 28]      (15,350)             False\n",
              "│    │    └─MBConv (1)                                       [1, 40, 28, 28]      [1, 40, 28, 28]      (31,290)             False\n",
              "│    └─Sequential (4)                                        [1, 40, 28, 28]      [1, 80, 14, 14]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 40, 28, 28]      [1, 80, 14, 14]      (37,130)             False\n",
              "│    │    └─MBConv (1)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n",
              "│    │    └─MBConv (2)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n",
              "│    └─Sequential (5)                                        [1, 80, 14, 14]      [1, 112, 14, 14]     --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 80, 14, 14]      [1, 112, 14, 14]     (126,004)            False\n",
              "│    │    └─MBConv (1)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n",
              "│    │    └─MBConv (2)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n",
              "│    └─Sequential (6)                                        [1, 112, 14, 14]     [1, 192, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 112, 14, 14]     [1, 192, 7, 7]       (262,492)            False\n",
              "│    │    └─MBConv (1)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n",
              "│    │    └─MBConv (2)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n",
              "│    │    └─MBConv (3)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n",
              "│    └─Sequential (7)                                        [1, 192, 7, 7]       [1, 320, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 192, 7, 7]       [1, 320, 7, 7]       (717,232)            False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]       [1, 1280, 7, 7]      --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 320, 7, 7]       [1, 1280, 7, 7]      (409,600)            False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]      [1, 1280, 7, 7]      (2,560)              False\n",
              "│    │    └─SiLU (2)                                         [1, 1280, 7, 7]      [1, 1280, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]      [1, 1280, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1280]            [1, 1000]            --                   True\n",
              "│    └─Dropout (0)                                           [1, 1280]            [1, 1280]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1280]            [1, 1000]            1,281,000            True\n",
              "============================================================================================================================================\n",
              "Total params: 5,288,548\n",
              "Trainable params: 1,281,000\n",
              "Non-trainable params: 4,007,548\n",
              "Total mult-adds (M): 385.87\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 107.89\n",
              "Params size (MB): 21.15\n",
              "Estimated Total Size (MB): 129.64\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YCy3uKLml8B",
        "outputId": "ee192fef-615c-4a77-d18f-9d2f220b1233"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.2, inplace=True)\n",
              "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_names)"
      ],
      "metadata": {
        "id": "aoIMk2D7aR07",
        "outputId": "a9f41e37-f40b-4bad-ec41-361c6e9204a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the classifier head of our model to suit our problem\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True),\n",
        "    nn.Linear(in_features=1280, # feature vectgor coming in\n",
        "              out_features=len(class_names))).to(device)"
      ],
      "metadata": {
        "id": "1np4IyviY1UT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "id": "c-BCrAONapR0",
        "outputId": "e6e4b860-25d6-4cbc-9627-2abaffb1cda7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.2, inplace=True)\n",
              "  (1): Linear(in_features=1280, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(1, 3, 224, 224), # Example of [batch_size, color_channels, height, width]\n",
        "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "        col_width=20,\n",
        "        row_settings=['var_names'])"
      ],
      "metadata": {
        "id": "VPrVA34baqup",
        "outputId": "da720f45-dfb6-4b37-f168-88dc6d248fe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 3]               --                   Partial\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1280, 7, 7]      --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 40, 28, 28]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 40, 28, 28]      (15,350)             False\n",
              "│    │    └─MBConv (1)                                       [1, 40, 28, 28]      [1, 40, 28, 28]      (31,290)             False\n",
              "│    └─Sequential (4)                                        [1, 40, 28, 28]      [1, 80, 14, 14]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 40, 28, 28]      [1, 80, 14, 14]      (37,130)             False\n",
              "│    │    └─MBConv (1)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n",
              "│    │    └─MBConv (2)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      (102,900)            False\n",
              "│    └─Sequential (5)                                        [1, 80, 14, 14]      [1, 112, 14, 14]     --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 80, 14, 14]      [1, 112, 14, 14]     (126,004)            False\n",
              "│    │    └─MBConv (1)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n",
              "│    │    └─MBConv (2)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     (208,572)            False\n",
              "│    └─Sequential (6)                                        [1, 112, 14, 14]     [1, 192, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 112, 14, 14]     [1, 192, 7, 7]       (262,492)            False\n",
              "│    │    └─MBConv (1)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n",
              "│    │    └─MBConv (2)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n",
              "│    │    └─MBConv (3)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       (587,952)            False\n",
              "│    └─Sequential (7)                                        [1, 192, 7, 7]       [1, 320, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 192, 7, 7]       [1, 320, 7, 7]       (717,232)            False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]       [1, 1280, 7, 7]      --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 320, 7, 7]       [1, 1280, 7, 7]      (409,600)            False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]      [1, 1280, 7, 7]      (2,560)              False\n",
              "│    │    └─SiLU (2)                                         [1, 1280, 7, 7]      [1, 1280, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]      [1, 1280, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1280]            [1, 3]               --                   True\n",
              "│    └─Dropout (0)                                           [1, 1280]            [1, 1280]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1280]            [1, 3]               3,843                True\n",
              "============================================================================================================================================\n",
              "Total params: 4,011,391\n",
              "Trainable params: 3,843\n",
              "Non-trainable params: 4,007,548\n",
              "Total mult-adds (M): 384.59\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 107.88\n",
              "Params size (MB): 16.05\n",
              "Estimated Total Size (MB): 124.53\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_c_Xd7gav_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}